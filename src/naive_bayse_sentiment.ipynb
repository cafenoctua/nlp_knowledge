{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴抽出を改良による極性判定の精度向上確認\n",
    "\n",
    "scikit-learnを用いて自然言語の極性判定を実装します。また、Bag of Wordsにおける特徴の表現方法によって正解率が変化することを確認します。\n",
    "今回はテストデータは用いず、10分割交差検証による正解率の平均を確認します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ準備\n",
    "\n",
    "今回用いるデータセット「MovieReview」の取得です。パッケージを用いてデータセットをダウンロードします。\n",
    "\n",
    "取得できるデータの種類についての説明と提供元のURLが確認できます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About Moview Review Data\n",
      "movie review data is annotated by 3 kinds of label (polarity, subjective rating, subjectivity).\n",
      "see also: http://www.cs.cornell.edu/people/pabo/movie-review-data/\n"
     ]
    }
   ],
   "source": [
    "import chazutsu\n",
    "chazutsu.datasets.MovieReview.polarity().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ダウンロードされたデータはローカルに展開されると同時に、\n",
    "シャッフル・訓練データとテストデータの分割されます。\n",
    "また、pandas形式で読込を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make directory for download at /media/brunolw/D/knowledge/nlp_knowledge/src.\n",
      "Begin downloading the Moview Review Data dataset from http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz.\n",
      "The dataset is saved to /media/brunolw/D/knowledge/nlp_knowledge/src/data/moview_review_data_polarity/review_polarity.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15bc2a105f54c439acf2e2a58e15b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3053.943359375), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting negative data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26dfe91c90ba4ba184ed5943f88b47ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting positive data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175df7b7403247b1bfd74fefe3990f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shuffle the extracted dataset.\n",
      "Done all process! Make below files at /media/brunolw/D/knowledge/nlp_knowledge/src/data/moview_review_data_polarity\n",
      " review_polarity.txt\n"
     ]
    }
   ],
   "source": [
    "r = chazutsu.datasets.MovieReview.polarity().download(force=True, test_size=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ダウンロードされたデータを先頭から5件確認します。\n",
    "レビュー内容が「review」、極性が「polarity」として「0(ネガティブ)」、「1(ポジティブ)」として格納されています。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>hedwig and the angry inch ( 2001 ) john camero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>as fairy tales go , cinderella has to be one o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>what surprises me most about the long-awaited ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>movies can do the two big es very well : educa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>there's something about ben stiller that makes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                             review\n",
       "0         1  hedwig and the angry inch ( 2001 ) john camero...\n",
       "1         1  as fairy tales go , cinderella has to be one o...\n",
       "2         1  what surprises me most about the long-awaited ...\n",
       "3         0  movies can do the two big es very well : educa...\n",
       "4         1  there's something about ben stiller that makes..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.data().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(r.data()['review'], r.data()['polarity'], test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル作成\n",
    "\n",
    "特徴抽出とモデル選択をパイプラインとして作成します。\n",
    "今回はCountVectorizerとでBag of Words形式に変換します。（TfidfTransformerでtfidf重み付けも行っています）\n",
    "\n",
    "単語の数え方における「単語まとまりの単位(1単語 or 2単語)」、「数え方の表現(N回 or 出現有無)」を組み合わせて4パターンのモデルを用意し、精度を比較します。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1単語・N回モデル\n",
    "\n",
    "文書の特徴量として単語まとまりの単位は1単語(unigram)、単語の出現回数をN回としてカウントするBoWを用いるモデル。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def build_pipeline_unigram_multicount():\n",
    "    text_clf = Pipeline([('vect', CountVectorizer(token_pattern=r'[A-Za-z_]+')),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    "    ])\n",
    "    return text_clf\n",
    "\n",
    "text_clf_unigram_multicount = build_pipeline_unigram_multicount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1単語・出現有無モデル\n",
    "\n",
    "文書の特徴量として単語まとまりの単位は1単語(unigram)、単語の出現回数を出現有無としてカウントするBoWを用いるモデル。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline_unigram_binarycount():    \n",
    "    text_clf = Pipeline([('vect', CountVectorizer(binary=True, token_pattern=r'[A-Za-z_]+'),),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    "    ])\n",
    "    return text_clf\n",
    "\n",
    "text_clf_unigram_binarycount = build_pipeline_unigram_binarycount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2単語・N回モデル\n",
    "\n",
    "文書の特徴量として単語まとまりの単位は2単語(unigram)、単語の出現回数をN回としてカウントするBoWを用いるモデル。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline_bigram_multicount():    \n",
    "    text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(2,2), token_pattern=r'[A-Za-z_]+'),),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    "    ])\n",
    "    return text_clf\n",
    "\n",
    "text_clf_bigram_multicount = build_pipeline_bigram_multicount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2単語・出現有無モデル\n",
    "\n",
    "文書の特徴量として単語まとまりの単位は2単語(unigram)、単語の出現回数を出現有無としてカウントするBoWを用いるモデル。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline_bigram_binarycount():    \n",
    "    text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(2,2), binary=True,token_pattern=r'[A-Za-z_]+'),),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB()),\n",
    "    ])\n",
    "    return text_clf\n",
    "\n",
    "text_clf_bigram_binarycount = build_pipeline_bigram_binarycount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validationによる正解率確認\n",
    "\n",
    "作成した4つのモデルの正解率を10分割交差検証で確認します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1単語・N回モデル\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80625, 0.85   , 0.75625, 0.7625 , 0.8125 , 0.80625, 0.8375 ,\n",
       "       0.8375 , 0.80625, 0.79375])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(text_clf_unigram_multicount, X_train, y_train, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.807 (+/- 0.058)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1単語・出現有無モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81875, 0.86875, 0.775  , 0.775  , 0.83125, 0.81875, 0.825  ,\n",
       "       0.84375, 0.86875, 0.7875 ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(text_clf_unigram_binarycount, X_train, y_train, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.821 (+/- 0.065)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2単語・N回モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73125, 0.8    , 0.70625, 0.71875, 0.76875, 0.7625 , 0.80625,\n",
       "       0.825  , 0.80625, 0.7375 ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(text_clf_bigram_multicount, X_train, y_train, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.766 (+/- 0.079)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2単語・出現有無モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76875, 0.83125, 0.7375 , 0.73125, 0.8    , 0.7875 , 0.825  ,\n",
       "       0.8    , 0.8375 , 0.725  ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(text_clf_bigram_binarycount, X_train, y_train, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.784 (+/- 0.080)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
